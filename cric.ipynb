{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4 as bs\n",
    "import urllib.request\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping \n",
    "\n",
    "def scraper(x,y,proxy):\n",
    "    \n",
    "    global all\n",
    "\n",
    "    for yr in range(x,y,1):\n",
    "        site=f'http://stats.espncricinfo.com/ci/engine/records/averages/batting.html?class=2;id={yr};type=year'\n",
    "        response = requests.get(site,proxies={\"http\": proxy})\n",
    "\n",
    "        soup=bs.BeautifulSoup(response.text,'lxml')\n",
    "        #sauce=urllib.request.urlopen(site).read()\n",
    "        #soup=bs.BeautifulSoup(sauce,'lxml')\n",
    "\n",
    "        table=soup.find('table')\n",
    "        #print(table)\n",
    "        table_rows=soup.find_all('tr')\n",
    "        #odi=[]\n",
    "\n",
    "\n",
    "        for tr in table_rows: \n",
    "            td=tr.find_all('td')\n",
    "\n",
    "            rows=[i.text for i in td if i.text[0]!='\\n']\n",
    "            #print(rows)\n",
    "            #print(len(rows))\n",
    "            if len(rows)!=0:\n",
    "                #print(rows[0])\n",
    "                players=rows[0]\n",
    "                runs=rows[4]\n",
    "                if runs!='-':\n",
    "                    #print(players,runs)\n",
    "                    all.append((yr,players,runs))\n",
    "\n",
    "        time.sleep(2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#df=pd.DataFrame(odi,columns=columns)\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from lxml.html import fromstring\n",
    "import requests\n",
    "from itertools import cycle\n",
    "import traceback\n",
    "\n",
    "\n",
    "def get_proxies():\n",
    "    url = 'https://free-proxy-list.net/'\n",
    "    response = requests.get(url)\n",
    "    parser = fromstring(response.text)\n",
    "    proxies = set()\n",
    "    for i in parser.xpath('//tbody/tr')[:10]:\n",
    "        if i.xpath('.//td[7][contains(text(),\"no\")]'):\n",
    "            proxy = \":\".join([i.xpath('.//td[1]/text()')[0], i.xpath('.//td[2]/text()')[0]])\n",
    "            proxies.add(proxy)\n",
    "    return proxies\n",
    "\n",
    "\n",
    "proxies = get_proxies()\n",
    "proxy_pool = cycle(proxies)\n",
    "l=1971\n",
    "columns=['Year','Player', 'Runs']\n",
    "all=[]\n",
    "for i in range(1,11):\n",
    "    #Get a proxy from the pool\n",
    "    proxy = next(proxy_pool)\n",
    "    print(\"Request #%d\"%i)\n",
    "    u=l+4\n",
    "    try:\n",
    "        #response = requests.get(url,proxies={\"http\": proxy, \"https\": proxy})\n",
    "        #print(response.json())\n",
    "        if u<=2020:    \n",
    "            print(l,u)\n",
    "            scraper(l,u,proxy)\n",
    "            l=u\n",
    "    except:\n",
    "            print(\"Skipping. Connnection error\")\n",
    "            #i=i-1\n",
    "\n",
    "df=pd.DataFrame(all,columns=columns)        \n",
    "df.to_csv('odi.csv',index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
